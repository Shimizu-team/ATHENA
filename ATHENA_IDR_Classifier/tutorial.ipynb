{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATHENA: Residue-Level IDR Classification Tutorial\n",
    "This Google Colab notebook provides a step-by-step guide for running the ATHENA residue-level (per-amino-acid) classifier (ATHENA_IDR_classification.py).\n",
    "\n",
    "This pipeline operates in two main stages:\n",
    "\n",
    "1. **Embedding Generation:** It uses an ESM model (e.g., esmc_300m) to generate per-residue embeddings for each protein in your FASTA file.\n",
    "\n",
    "2. **IDR Prediction:** It feeds these embeddings into the trained Bi-LSTM + Transformer model to predict a disorder score and label for every single residue.\n",
    "\n",
    "### Expected Runtime\n",
    "\n",
    "**Anywhere from 1-10 minutes**, depending on the number of sequences to be classified.\n",
    "\n",
    "### Step 1: Clone Repository and Set Up Environment\n",
    "First, we will clone the ATHENA GitHub repository, move into the new directory, and install the required Python libraries. This includes the esm library, which is required for generating protein embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone the Repository\n",
    "\n",
    "!git clone https://github.com/Shimizu-team/ATHENA\n",
    "%cd ATHENA\n",
    "\n",
    "# 2. Install Dependencies\n",
    "!pip install torch pandas esm httpx tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Python Scripts\n",
    "The main script ATHENA_IDR_classification.py imports the model architecture from a file named Transformer_LSTM.py. The repository contains this model in ATHENA_IDR_Model.py.\n",
    "\n",
    "We rename this file before we import the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Model Script for Import\n",
    "import os\n",
    "\n",
    "model_source = \"ATHENA_IDR_Model.py\"\n",
    "model_target = \"Transformer_LSTM.py\"\n",
    "\n",
    "if os.path.exists(model_source):\n",
    "    !mv {model_source} {model_target}\n",
    "    print(f\"Renamed '{model_source}' to '{model_target}' for import.\")\n",
    "else:\n",
    "    print(f\"Could not find '{model_source}'. Did the git clone fail or was the file misnamed?\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import Libraries\n",
    "We import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "# Import the main function\n",
    "try:\n",
    "    # We rename the import for clarity\n",
    "    from ATHENA_IDR_classification import main as run_idr_prediction\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Please ensure 'Transformer_LSTM.py' (renamed from 'ATHENA_IDR_Model.py') is present.\")\n",
    "\n",
    "print(\"Core modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare Model Parameters\n",
    "Now we will unzip the model weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and the zip file\n",
    "model_dir = \"ATHENA_IDR_model_params\"\n",
    "zip_filename = \"ATHENA_IDR_Weights.pt.zip\"\n",
    "zip_filepath = os.path.join(model_dir, zip_filename)\n",
    "\n",
    "print(f\"Attempting to unzip '{zip_filepath}' into its parent directory '{model_dir}'...\")\n",
    "\n",
    "# Check if the zip file exists at the specified path\n",
    "if not os.path.isfile(zip_filepath):\n",
    "    print(f\"\\nError: File not found at '{zip_filepath}'.\")\n",
    "    print(\"Please ensure the GitHub repository was cloned correctly and this file exists.\")\n",
    "else:\n",
    "    print(f\"\\nExtracting '{zip_filepath}'...\")\n",
    "    \n",
    "    !unzip -q -o \"{zip_filepath}\" -d \"{model_dir}\"\n",
    "    \n",
    "    print(f\"Unzip command finished. Files extracted to '{model_dir}'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define Run Configuration\n",
    "The original `ATHENA_IDR_classification.py` script is designed to be run from the command line. We define the run configurations here. \n",
    "\n",
    "We designate the input fasta file using the --fasta_file config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Cell 6: Define Configuration (via sys.argv)\n",
    "import sys\n",
    "\n",
    "# These arguments match the 'README' and the script defaults\n",
    "args_list = [\n",
    "    'ATHENA_IDR_classification.py',\n",
    "    \n",
    "    '--fasta_file',\n",
    "    'input/example_sequences.fasta',\n",
    "    \n",
    "    '--idr_model_path',\n",
    "    'ATHENA_IDR_model_params/ATHENA_IDR_Weights.pt', \n",
    "    \n",
    "    '--output_csv',\n",
    "    'output/IDR_predictions.csv',\n",
    "    \n",
    "    '--esm_model_name',\n",
    "    'esmc_300m', \n",
    "    \n",
    "    '--batch_size',\n",
    "    '8'\n",
    "]\n",
    "\n",
    "# Set sys.argv\n",
    "sys.argv = args_list\n",
    "\n",
    "print(\"--- Running Configuration ---\")\n",
    "print(\" \".join(args_list))\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Run Prediction \n",
    "With all configuration set, we can now call the main function from the script. This will execute the full pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Cell 7: Execute Prediction\n",
    "print(\"Starting End-to-End IDR Prediction\")\n",
    "print(\"STEP 1: Generating Protein Embeddings (this may take time)...\")\n",
    "\n",
    "try:\n",
    "    # Call the main function we imported\n",
    "    run_idr_prediction()\n",
    "    print(\"\\nPipeline Complete\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Error: 'EnhancedLSTMTransformerIDRPredictor' not found.\")\n",
    "    print(\"Please ensure Step 2 (renaming the .py file) completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 Review and Interpret Results\n",
    "The script saves all predictions to a single CSV file. We load it with pandas to see the results.\n",
    "\n",
    "The output contains one row for every amino acid in your input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Cell 8: Load and Display Results\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "output_file = 'output/IDR_predictions.csv'\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    print(f\"Loading results from '{output_file}'...\")\n",
    "    \n",
    "    df = pd.read_csv(output_file)\n",
    "    \n",
    "    print(f\"\\nTotal residues predicted: {len(df)}\")\n",
    "    \n",
    "    # Display the first 20 predictions\n",
    "    print(\"\\n--- First 20 Residue Predictions ---\")\n",
    "    print(df.head(20).to_markdown(index=False))\n",
    "    \n",
    "    # Display predictions for the start of the second protein\n",
    "    print(\"\\n--- Predictions for 'protein_sample_02' ---\")\n",
    "    print(df[df['Protein ID'] == 'protein_sample_02'].head(20).to_markdown(index=False))\n",
    "\n",
    "else:\n",
    "    print(f\"Output file '{output_file}' not found.\")\n",
    "    print(\"Please ensure Step 7 completed without errors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tardigrada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
